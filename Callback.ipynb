{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Callback.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNIxm2AJjhXBs60XNsZ0M3z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DommiiUdomp/-/blob/main/Callback.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdauww_cTom4"
      },
      "source": [
        "## Example **Callback**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPGd1rivTsqQ"
      },
      "source": [
        "#Load the data set\n",
        "import tensorflow as tf\n",
        "from sklearn.datasets import load_diabetes"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCLzs8V1T64J"
      },
      "source": [
        "data_diabets = load_diabetes()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQNIehU_T_yz"
      },
      "source": [
        "\n",
        "#save input and target variables\n",
        "data = data_diabets['data']\n",
        "target = data_diabets['target']"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJQedhh0UClW"
      },
      "source": [
        "#nomalize the target\n",
        "\n",
        "target_normalize = (target - target.mean(axis = 0)) / target.std()\n",
        "\n",
        "#slite train and test data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data, test_data, train_target, test_target = train_test_split(data, target_normalize, test_size = 0.1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swYgI7CZUNp0"
      },
      "source": [
        "#Build the model \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "def get_model_1(wight_d_1, rate) :\n",
        "  model_1 = Sequential ( [ \n",
        "                          Dense (128, activation = 'relu' , kernel_regularizer = tf.keras.regularizers.l2(wight_d_1),\n",
        "                               input_shape = (train_data.shape[1], ) ),\n",
        "                          Dropout (rate) ,\n",
        "                          Dense (128, activation = 'relu' , kernel_regularizer = tf.keras.regularizers.l2(wight_d_1)),\n",
        "                          Dropout (rate) ,\n",
        "                          Dense (128, activation = 'relu' , kernel_regularizer = tf.keras.regularizers.l2(wight_d_1)),\n",
        "                          Dropout (rate) ,\n",
        "                          Dense (128, activation = 'relu' , kernel_regularizer = tf.keras.regularizers.l2(wight_d_1)),\n",
        "                          Dropout (rate) ,\n",
        "                          Dense (128, activation = 'relu' , kernel_regularizer = tf.keras.regularizers.l2(wight_d_1)),\n",
        "                          Dropout (rate) ,\n",
        "                          Dense (128, activation = 'relu' , kernel_regularizer = tf.keras.regularizers.l2(wight_d_1)),\n",
        "                          Dropout (rate) ,\n",
        "                          Dense (1, name = 'output') \n",
        "  ])\n",
        "  return model_1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6P9e2MoLVk_A"
      },
      "source": [
        "## Train **Callback**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTFB0ffRVaO4"
      },
      "source": [
        "#train CALLBACK\n",
        "\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "class trainingCallback (Callback) :\n",
        "\n",
        "  def on_train_begin(self , logs = None) :\n",
        "    print ('.....starting training.......')\n",
        "\n",
        "  def on_epoch_begin(self , epoch , logs = None) :\n",
        "    print (f'.....starting epoch.......{epoch}')\n",
        "\n",
        "  def on_train_batch_begin(self, batch, logs = None) :\n",
        "    print (f'.....training: starting batch.......{batch}')\n",
        "  \n",
        "  def on_train_batch_end(self, batch, logs = None) :\n",
        "    print (f'.....training: finished batch.......{batch}')\n",
        "    \n",
        "  def on_epoch_end(self, epoch, logs = None) :\n",
        "    print (f'.....finished epoch.......{epoch}')\n",
        "\n",
        "  def on_train_end(self, logs = None) :\n",
        "    print (f'.....finished training!!!')\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMVPFZZCb5iw",
        "outputId": "ae3681e3-4eec-4bdd-c53d-0305be71028b"
      },
      "source": [
        "#rebuild\n",
        "model_1 = get_model_1(0.00001, 0.5) \n",
        "print (model_1.summary())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 128)               1408      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 84,097\n",
            "Trainable params: 84,097\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fflKErKRb5v0"
      },
      "source": [
        "#compile\n",
        "model_1.compile (optimizer = 'adam' , loss ='mse' )"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qw642N_7XeMj",
        "outputId": "ebdbef81-9088-4716-f0f8-9cfabcae4a20"
      },
      "source": [
        "model_1.fit(train_data, train_target, epochs=3, batch_size=128, verbose=False, callbacks=[trainingCallback()])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".....starting training.......\n",
            ".....starting epoch.......0\n",
            ".....training: starting batch.......0\n",
            ".....training: finished batch.......0\n",
            ".....training: starting batch.......1\n",
            ".....training: finished batch.......1\n",
            ".....training: starting batch.......2\n",
            ".....training: finished batch.......2\n",
            ".....training: starting batch.......3\n",
            ".....training: finished batch.......3\n",
            ".....finished epoch.......0\n",
            ".....starting epoch.......1\n",
            ".....training: starting batch.......0\n",
            ".....training: finished batch.......0\n",
            ".....training: starting batch.......1\n",
            ".....training: finished batch.......1\n",
            ".....training: starting batch.......2\n",
            ".....training: finished batch.......2\n",
            ".....training: starting batch.......3\n",
            ".....training: finished batch.......3\n",
            ".....finished epoch.......1\n",
            ".....starting epoch.......2\n",
            ".....training: starting batch.......0\n",
            ".....training: finished batch.......0\n",
            ".....training: starting batch.......1\n",
            ".....training: finished batch.......1\n",
            ".....training: starting batch.......2\n",
            ".....training: finished batch.......2\n",
            ".....training: starting batch.......3\n",
            ".....training: finished batch.......3\n",
            ".....finished epoch.......2\n",
            ".....finished training!!!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f77884cd490>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FFqTYKfX9jf"
      },
      "source": [
        "#Evaluate CALLBACK\n",
        "\n",
        "class testingCallback (Callback) :\n",
        "\n",
        "  def on_test_begin(self , logs = None) :\n",
        "    print ('.....starting testing.......')\n",
        "\n",
        "  def on_test_batch_begin(self, batch, logs = None) :\n",
        "    print (f'.....testing: starting batch.......{batch}')\n",
        "  \n",
        "  def on_test_batch_end(self, batch, logs = None) :\n",
        "    print (f'.....testing: finished batch.......{batch}')\n",
        "\n",
        "  def on_test_end(self, logs = None) :\n",
        "    print (f'.....finished testing!!!')\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQBC0qEAZOzQ",
        "outputId": "a3a070ae-7160-4f56-8221-92e2d6473924"
      },
      "source": [
        "model_1.evaluate(test_data,test_target, verbose=False, callbacks=[testingCallback()])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".....starting testing.......\n",
            ".....testing: starting batch.......0\n",
            ".....testing: finished batch.......0\n",
            ".....testing: starting batch.......1\n",
            ".....testing: finished batch.......1\n",
            ".....finished testing!!!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8574028015136719"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWopBoigZhJK"
      },
      "source": [
        "#Prediction CALLBACK\n",
        "\n",
        "class predictionCallback (Callback) :\n",
        "\n",
        "  def on_prediction_begin(self , logs = None) :\n",
        "    print ('.....starting prediction.......')\n",
        "\n",
        "  def on_prediction_batch_begin(self, batch, logs = None) :\n",
        "    print (f'.....prediction: starting batch.......{batch}')\n",
        "  \n",
        "  def on_prediction_batch_end(self, batch, logs = None) :\n",
        "    print (f'.....prediction: finished batch.......{batch}')\n",
        "\n",
        "  def on_prediction_end(self, logs = None) :\n",
        "    print (f'.....finished prediction!!!')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICAnqFgeZ8tX",
        "outputId": "e4a87efd-342a-4ac9-a849-23045b42fe8a"
      },
      "source": [
        "model_1.predict(test_data, verbose=False, callbacks=[predictionCallback()])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.0097247 ],\n",
              "       [-0.01092893],\n",
              "       [-0.01013372],\n",
              "       [-0.01062188],\n",
              "       [-0.01422403],\n",
              "       [-0.00978642],\n",
              "       [-0.01174563],\n",
              "       [-0.01461069],\n",
              "       [-0.01139403],\n",
              "       [-0.0101269 ],\n",
              "       [-0.00678477],\n",
              "       [-0.0076749 ],\n",
              "       [-0.00764565],\n",
              "       [-0.01192037],\n",
              "       [-0.01122787],\n",
              "       [-0.01171062],\n",
              "       [-0.01022101],\n",
              "       [-0.01625525],\n",
              "       [-0.01454767],\n",
              "       [-0.01006221],\n",
              "       [-0.01042601],\n",
              "       [-0.01064751],\n",
              "       [-0.01511134],\n",
              "       [-0.01022002],\n",
              "       [-0.01722736],\n",
              "       [-0.01115946],\n",
              "       [-0.01482133],\n",
              "       [-0.01249191],\n",
              "       [-0.01050388],\n",
              "       [-0.01797077],\n",
              "       [-0.01035688],\n",
              "       [-0.00983291],\n",
              "       [-0.01249576],\n",
              "       [-0.01296179],\n",
              "       [-0.01057144],\n",
              "       [-0.01125003],\n",
              "       [-0.01537305],\n",
              "       [-0.01480097],\n",
              "       [-0.00891376],\n",
              "       [-0.0117582 ],\n",
              "       [-0.01149649],\n",
              "       [-0.01214496],\n",
              "       [-0.00967516],\n",
              "       [-0.01102805],\n",
              "       [-0.01371835]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vDn1Zo_aItb"
      },
      "source": [
        "def get_model_1(wight_d_1, rate) :\n",
        "  model_1 = Sequential ( [ \n",
        "                          Dense (128, activation = 'relu' , kernel_regularizer = tf.keras.regularizers.l2(wight_d_1),\n",
        "                               input_shape = (train_data.shape[1], ) ),\n",
        "                          Dropout (rate) ,\n",
        "                          Dense (128, activation = 'relu' , kernel_regularizer = tf.keras.regularizers.l2(wight_d_1)),\n",
        "                          Dropout (rate) ,\n",
        "                          Dense (128, activation = 'relu' , kernel_regularizer = tf.keras.regularizers.l2(wight_d_1)),\n",
        "                          Dropout (rate) ,\n",
        "                          Dense (128, activation = 'relu' , kernel_regularizer = tf.keras.regularizers.l2(wight_d_1)),\n",
        "                          Dropout (rate) ,\n",
        "                          Dense (128, activation = 'relu' , kernel_regularizer = tf.keras.regularizers.l2(wight_d_1)),\n",
        "                          Dropout (rate) ,\n",
        "                          Dense (128, activation = 'relu' , kernel_regularizer = tf.keras.regularizers.l2(wight_d_1)),\n",
        "                          Dropout (rate) ,\n",
        "                          Dense (1, name = 'output') \n",
        "  ])\n",
        "  return model_1"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aZfRdzwVnQV"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SGZqCbqi56g"
      },
      "source": [
        "# **Additional Callback**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dO083Kefi95K"
      },
      "source": [
        "Learning rate scheduler\n",
        "Usage: tf.keras.callbacks.LearningRateScheduler(schedule, verbose=0)\n",
        "\n",
        "The learning rate scheduler that we implemented in the previous reading as a custom callback is also available as a built in callback.\n",
        "\n",
        "As in our custom callback, the LearningRateScheduler in Keras takes a function schedule as an argument.\n",
        "\n",
        "This function schedule should take two arguments:\n",
        "\n",
        "The current epoch (as an integer), and\n",
        "The current learning rate,\n",
        "and return new learning rate for that epoch.\n",
        "\n",
        "The LearningRateScheduler also has an optional verbose argument, which prints information about the learning rate if it is set to 1.\n",
        "\n",
        "Let's see a simple example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DY4P3utjS3P"
      },
      "source": [
        "# Define the learning rate schedule function\n",
        "\n",
        "def lr_function(epoch, lr):\n",
        "    if epoch % 2 == 0:\n",
        "        return lr\n",
        "    else:\n",
        "        return lr + epoch/1000"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLLTwlrcjVNN",
        "outputId": "ad52c602-fad9-4eee-c01d-daf2063957b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Build the model\n",
        "model = tf.keras.Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(train_data.shape[1],)),\n",
        "    Dense(64,activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1)        \n",
        "])\n",
        "#compile\n",
        "model.compile(optimizer='adam', loss ='mse', metrics=[\"mse\",\"mae\"])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_data, train_target, epochs=10,\n",
        "                    callbacks=[tf.keras.callbacks.LearningRateScheduler(lr_function, verbose=1)], verbose=False)\n",
        "\n",
        "history = model.fit(train_data, train_target, epochs=10,\n",
        "                    callbacks=[tf.keras.callbacks.LearningRateScheduler(lambda x:1/(3+5*x), verbose=1)], \n",
        "                    verbose=False)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0020000000474974513.\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0020000000949949026.\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.005000000094994903.\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.004999999888241291.\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.009999999888241292.\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.01699999977648258.\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.016999999061226845.\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.025999999061226846.\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.3333333333333333.\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.125.\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.07692307692307693.\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.05555555555555555.\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.043478260869565216.\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.03571428571428571.\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.030303030303030304.\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.02631578947368421.\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.023255813953488372.\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.020833333333333332.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuDCO9SgjnEL"
      },
      "source": [
        "## CSV logger"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayyNUg_gjXYu"
      },
      "source": [
        "# Train the model with a CSV logger\n",
        "\n",
        "history = model.fit(train_data, train_target, epochs=10,\n",
        "                    callbacks=[tf.keras.callbacks.CSVLogger(\"results.csv\")], verbose=False)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnJE8mqwkNA5",
        "outputId": "a8c56c4c-f8ad-4862-abf2-096aaf7ccd14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "# Load the CSV\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "pd.read_csv(\"results.csv\", index_col='epoch')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>mae</th>\n",
              "      <th>mse</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.483635</td>\n",
              "      <td>0.565290</td>\n",
              "      <td>0.483635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.488943</td>\n",
              "      <td>0.564854</td>\n",
              "      <td>0.488943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.480452</td>\n",
              "      <td>0.561969</td>\n",
              "      <td>0.480452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.477558</td>\n",
              "      <td>0.559491</td>\n",
              "      <td>0.477558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.479184</td>\n",
              "      <td>0.558060</td>\n",
              "      <td>0.479184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.478058</td>\n",
              "      <td>0.559009</td>\n",
              "      <td>0.478058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.474789</td>\n",
              "      <td>0.556274</td>\n",
              "      <td>0.474789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.479999</td>\n",
              "      <td>0.554812</td>\n",
              "      <td>0.479999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.478709</td>\n",
              "      <td>0.558111</td>\n",
              "      <td>0.478709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.484379</td>\n",
              "      <td>0.557518</td>\n",
              "      <td>0.484379</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           loss       mae       mse\n",
              "epoch                              \n",
              "0      0.483635  0.565290  0.483635\n",
              "1      0.488943  0.564854  0.488943\n",
              "2      0.480452  0.561969  0.480452\n",
              "3      0.477558  0.559491  0.477558\n",
              "4      0.479184  0.558060  0.479184\n",
              "5      0.478058  0.559009  0.478058\n",
              "6      0.474789  0.556274  0.474789\n",
              "7      0.479999  0.554812  0.479999\n",
              "8      0.478709  0.558111  0.478709\n",
              "9      0.484379  0.557518  0.484379"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAUhv9uikRb5"
      },
      "source": [
        "## Lambda callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyxBYImekVLv"
      },
      "source": [
        "# Print the epoch number at the beginning of each epoch\n",
        "\n",
        "epoch_callback = tf.keras.callbacks.LambdaCallback(\n",
        "    on_epoch_begin=lambda epoch,logs: print('Starting Epoch {}!'.format(epoch+1)))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KF8HQrsgkX00"
      },
      "source": [
        "# Print the loss at the end of each batch\n",
        "\n",
        "batch_loss_callback = tf.keras.callbacks.LambdaCallback(\n",
        "    on_batch_end=lambda batch,logs: print('\\n After batch {}, the loss is {:7.2f}.'.format(batch, logs['loss'])))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4mtaANlkZw6"
      },
      "source": [
        "# Inform that training is finished\n",
        "\n",
        "train_finish_callback = tf.keras.callbacks.LambdaCallback(\n",
        "    on_train_end=lambda logs: print('Training finished!'))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4hPbp26kbup",
        "outputId": "f5f7d1fc-3a81-4d1b-92b3-a65a414a6843",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Train the model with the lambda callbacks\n",
        "\n",
        "history = model.fit(train_data, train_target, epochs=5, batch_size=100,\n",
        "                    callbacks=[epoch_callback, batch_loss_callback,train_finish_callback], verbose=False)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Epoch 1!\n",
            "\n",
            " After batch 0, the loss is    0.44.\n",
            "\n",
            " After batch 1, the loss is    0.43.\n",
            "\n",
            " After batch 2, the loss is    0.49.\n",
            "\n",
            " After batch 3, the loss is    0.48.\n",
            "Starting Epoch 2!\n",
            "\n",
            " After batch 0, the loss is    0.46.\n",
            "\n",
            " After batch 1, the loss is    0.48.\n",
            "\n",
            " After batch 2, the loss is    0.49.\n",
            "\n",
            " After batch 3, the loss is    0.48.\n",
            "Starting Epoch 3!\n",
            "\n",
            " After batch 0, the loss is    0.48.\n",
            "\n",
            " After batch 1, the loss is    0.49.\n",
            "\n",
            " After batch 2, the loss is    0.49.\n",
            "\n",
            " After batch 3, the loss is    0.47.\n",
            "Starting Epoch 4!\n",
            "\n",
            " After batch 0, the loss is    0.47.\n",
            "\n",
            " After batch 1, the loss is    0.47.\n",
            "\n",
            " After batch 2, the loss is    0.48.\n",
            "\n",
            " After batch 3, the loss is    0.47.\n",
            "Starting Epoch 5!\n",
            "\n",
            " After batch 0, the loss is    0.59.\n",
            "\n",
            " After batch 1, the loss is    0.56.\n",
            "\n",
            " After batch 2, the loss is    0.51.\n",
            "\n",
            " After batch 3, the loss is    0.47.\n",
            "Training finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7yt3uxVkeZC"
      },
      "source": [
        "## Reduce learning rate on plateau"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VkI7atokkpz",
        "outputId": "f74fd783-528a-4690-e4f8-458d18cbc4c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Train the model with the ReduceLROnPlateau callback\n",
        "\n",
        "history = model.fit(train_data, train_target, epochs=100, batch_size=100,\n",
        "                    callbacks=[tf.keras.callbacks.ReduceLROnPlateau(\n",
        "                        monitor=\"loss\",factor=0.2, verbose=1)], verbose=False)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.00416666679084301.\n",
            "\n",
            "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.0008333333767950535.\n",
            "\n",
            "Epoch 00077: ReduceLROnPlateau reducing learning rate to 0.00016666667070239783.\n",
            "\n",
            "Epoch 00087: ReduceLROnPlateau reducing learning rate to 3.333333297632635e-05.\n",
            "\n",
            "Epoch 00097: ReduceLROnPlateau reducing learning rate to 6.666666740784422e-06.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfyVtGz0km9j"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}